{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VideoSHAP\n",
    "\n",
    "### Understanding What Vision Models See in Videos\n",
    "\n",
    "---\n",
    "\n",
    "**VideoSHAP** uses game-theoretic Shapley values to reveal which objects in a video are most important for a model's response.\n",
    "\n",
    "Given a video and a question, VideoSHAP:\n",
    "1. Segments and tracks objects across frames\n",
    "2. Tests how removing each object affects the model's answer\n",
    "3. Computes fair importance scores using Shapley values\n",
    "4. Visualizes results as an attention heatmap\n",
    "\n",
    "> **Analogy:** If your video is a movie scene, VideoSHAP tells you which actors are crucial for understanding the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = Path().resolve().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from IPython.display import Image as IPyImage, display\n",
    "\n",
    "from token_shap.video_shap import (\n",
    "    VideoSHAP,\n",
    "    SAM3VideoSegmentationModel,\n",
    "    VideoBlackoutManipulator,\n",
    "    GeminiVideoModel,\n",
    ")\n",
    "from token_shap.base import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys\n",
    "OPENAI_API_KEY = \"...\"\n",
    "GOOGLE_API_KEY = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Components\n",
    "\n",
    "VideoSHAP requires four components:\n",
    "\n",
    "| Component | Purpose | Model Used |\n",
    "|-----------|---------|------------|\n",
    "| **Segmentation** | Track objects across frames | SAM 3 |\n",
    "| **VLM** | Answer questions about video | Gemini 2.5 Flash |\n",
    "| **Manipulator** | Hide objects to test importance | Blackout (bbox) |\n",
    "| **Vectorizer** | Measure response similarity | OpenAI Embeddings |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation: SAM3 for video object tracking\n",
    "sam3_model = SAM3VideoSegmentationModel(\n",
    "    model_name=\"facebook/sam3\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# VLM: Gemini for video understanding\n",
    "vlm_model = GeminiVideoModel(\n",
    "    model_name=\"gemini-2.5-pro\",\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Manipulator: Blackout objects by bounding box\n",
    "manipulator = VideoBlackoutManipulator(\n",
    "    mask_type=\"bbox\",\n",
    "    preserve_overlapping=True,\n",
    ")\n",
    "\n",
    "# Vectorizer: OpenAI embeddings for similarity\n",
    "vectorizer = OpenAIEmbeddings(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"text-embedding-3-large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VideoSHAP analyzer\n",
    "video_shap = VideoSHAP(\n",
    "    model=vlm_model,\n",
    "    segmentation_model=sam3_model,\n",
    "    manipulator=manipulator,\n",
    "    vectorizer=vectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 1: Cats Watching a Flying Object\n",
    "\n",
    "A simple scene with cats tracking something flying across the frame.\n",
    "\n",
    "**Question:** *\"Describe to me the object flying in the video.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, shapley_values = video_shap.analyze(\n",
    "    video_path=\"../videos/cats.mp4\",\n",
    "    prompt=\"Describe to me the object flying in the video.\",\n",
    "    text_prompts=[\"animal\"],\n",
    "    target_fps=8,\n",
    "    max_combinations=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side visualization GIF (perfectly synchronized)\n",
    "gif_path = video_shap.create_side_by_side_gif(\n",
    "    output_path=\"../images/cats.gif\",\n",
    "    heatmap_opacity=0.5,\n",
    "    background_opacity=0.3,\n",
    ")\n",
    "\n",
    "display(IPyImage(filename=gif_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = video_shap.plot_importance_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 2: Birthday Party\n",
    "\n",
    "A more complex scene with multiple people, a cake, and various objects.\n",
    "\n",
    "**Question:** *\"Describe the birthday boy to me.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, shapley_values = video_shap.analyze(\n",
    "    video_path=\"../videos/birthday.mp4\",\n",
    "    prompt=\"Describe the birthday boy to me\",\n",
    "    text_prompts=[\"person\", \"cake\", \"gift\", \"balloon\"],\n",
    "    target_fps=8,\n",
    "    max_combinations=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side visualization GIF (perfectly synchronized)\n",
    "gif_path = video_shap.create_side_by_side_gif(\n",
    "    output_path=\"../images/birthday.gif\",\n",
    "    heatmap_opacity=0.5,\n",
    "    background_opacity=0.3,\n",
    ")\n",
    "\n",
    "display(IPyImage(filename=gif_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = video_shap.plot_importance_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploring Results\n",
    "\n",
    "After analysis, you can inspect the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View responses for different object combinations\n",
    "video_shap.results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Shapley values (importance scores)\n",
    "print(\"Object Importance Scores:\\n\")\n",
    "for obj, value in sorted(video_shap.shapley_values.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {obj}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reference\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "**`analyze()`**\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `video_path` | Path to input video | *required* |\n",
    "| `prompt` | Question to ask about the video | *required* |\n",
    "| `text_prompts` | Object categories to detect | *required* |\n",
    "| `target_fps` | Frames per second to process | 8 |\n",
    "| `max_combinations` | Max object subsets to test | 20 |\n",
    "\n",
    "**`create_side_by_side_gif()`**\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `output_path` | Output GIF path | *required* |\n",
    "| `heatmap_opacity` | Blend of heatmap colors | 0.5 |\n",
    "| `background_opacity` | Visibility of non-objects | 0.3 |\n",
    "\n",
    "### Tips\n",
    "\n",
    "- **Better detection:** Add more relevant categories to `text_prompts`\n",
    "- **Faster analysis:** Reduce `max_combinations` or `target_fps`\n",
    "- **More detail:** Increase `target_fps` for fast-moving scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "questions = [\n",
    "    \"Describe the character who pours the drink.\",\n",
    "    \"What is the man on the far left wearing?\",\n",
    "    \"In one word, who is the weirdest in the video?\",\n",
    "]\n",
    "\n",
    "text_prompts = [\"person\", \"alien\"]\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "    print(f\"\\n=== Question {i+1}: {q} ===\")\n",
    "\n",
    "    results_df, shapley_values = video_shap.analyze(\n",
    "        video_path=\"../videos/alien.mp4\",\n",
    "        prompt=q,\n",
    "        text_prompts=text_prompts,\n",
    "        target_fps=8,\n",
    "        max_combinations=20,\n",
    "    )\n",
    "\n",
    "    gif_path = video_shap.create_side_by_side_gif(\n",
    "        output_path=f\"../images/alien_q{i+1}.gif\",\n",
    "        heatmap_opacity=0.5,\n",
    "        background_opacity=0.3,\n",
    "    )\n",
    "\n",
    "    display(Image(filename=gif_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM3",
   "language": "python",
   "name": "sam3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
